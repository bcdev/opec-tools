General TODO:

- parse configuration from .ini-file or similar
- add logging; add log level parameter
- extend read mechanism by 'force' flag that, well, forces to read from disk, overwriting old values
- extend read mechanism by smarter caching means
- allow clearing of cache
- document how to work with the tool, i.e., create a dump of the console when doing something smart with the tool
- add parameter allowing to zip the output
- document the matchup strategy (see below) somewhere
- same holds for the benchmark computing strategy. Perhaps create that and circulate for comments?

Requirements:

allow easy access for user, including write access to data:
- data is a dictionary
- structure: varName -> numpyArray
- contains dedicated 'read' methods
    - 'read' reads from disk the given variable data, given by origin or shape (or fully)
    - puts the data into the dictionary, so it can be accessed without the need to be read again

don't read each pixel from disk:
- read variables always in chunks
- easy with structure described above

Matchup Strategy:
- user can specify a macro pixel size, a maximum geographic delta, a maximum time delta and a maximum depth delta
- for each reference record r from the file, the following is done:
    - in model data, find pixel closest to lat/lon position of r
    - take macro pixel
    - check all pixels of the macro pixel if they are inside the geographic, time and depth bounds
    - if yes: create matchup with reference value from r and model value from the pixel
    - thus: many model values may have the same reference value
    - put all matchups into a list

Benchmarks are computed like this:
- take all matchups
- create two arrays: one contains all reference values, the other all model values
- the same index in the arrays mean that the values belong together
- compute the benchmarks on these arrays
- thus: for each benchmarked variable, a single set of benchmarks (containing one value of RMSD, Bias, ...) is computed

Configuration:
- Configuration is fixed, attributes are 'final'
- Batch mode: create Configuration from file, hand it into Processor, MatchupEngine, Output etc

- Interactive mode: create Configuration objects from scratch
- put these objects into Processor, MatchupEngine, Output
- Processor, MatchupEngine, Output: if no configuration object is passed, take default one, same as in batch mode
--> user responsibility to put same config into output as into processor
- can buy that if there's the possibility to make a run with only one configuration object
- meaning: just run an 'Output' with data and configuration, and everything is consistent
- if the user wants to mess around, fine, but we cannot prevent him from creating inconsistent output by wrong usage

proposed output format:
- CSV containing statistics
- PNG images of target/taylor diagrams
- example CSV:

##############################################################
#
# Benchmarking results of file 'chl_DMI.nc'
#
##############################################################
#
# Created on Jan 02nd, 2013
#
# Matchup criteria:
#    macro pixel size = 3
#    maximum geographic delta = 10 "degrees"
#    maximum time delta = 20000 seconds
#    maximum depth delta = 10 meters
#
# Parameters:
#    Delta Degrees of Freedom (used for computation of stddev) = 1
#    alpha (used for percentile computation) = 0.4
#    beta (used for percentile computation) = 0.4
#
variable_name   reference_variable_name matchup_count   min max mean    stddev  median  p90 p95 ref_min ref_max ref_mean    ref_stddev  ref_median  ref_p90 ref_p95 rmsd    unbiased_rmsd   bias    pbias   correlation_coefficient reliability_index   model_efficiency
chl-a   chl_ref 10 0.1 0.2 0.3 0.4 0.5 0.6 0.7